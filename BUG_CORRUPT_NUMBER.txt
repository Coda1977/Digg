================================================================================
BUG: CORRUPT NUMBER VALUE CAUSING PDF CRASH
================================================================================

SYMPTOM:
--------
Error: unsupported number: -9.44473296573929e+21
    at number (db41b65e34727356.js:1:1146405)
    at db41b65e34727356.js:124:5833
    at Array.map (<anonymous>)
    at I4.transform (db41b65e34727356.js:124:5826)
    at I4.translate (db41b65e34727356.js:124:5912)
    at TEXT (db41b65e34727356.js:131:210)
    at Ea (db41b65e34727356.js:131:12561)

This error occurs when generating PDF reports via @react-pdf/renderer.

CURRENT STATUS:
---------------
❌ BUG STILL PRESENT (as of Jan 7, 2026)
Despite 8 commits attempting to fix this issue, the corrupt number -9.44e21
is still causing PDF crashes in production.

THE REAL ISSUE:
---------------
The corrupt number is being GENERATED BY THE AI MODEL during analysis, not
stored in the database initially. Every attempt to sanitize existing data
was a band-aid - we need to prevent the AI from generating corrupt values
in the first place OR catch them at the point of generation/storage.


================================================================================
CHRONOLOGY OF FAILED FIX ATTEMPTS
================================================================================

COMMIT 1: 047c28a (Tue Jan 6 08:48:13 2026)
-------------------------------------------
fix: add validation to PDF rating components to prevent render crashes

WHAT WE THOUGHT: Rating values in the database were corrupt
WHAT WE DID: Added validation to RatingBarChart, individual rating boxes,
             and RatingScalePdf components
FILES CHANGED:
  - src/components/pdf/ProjectInsightsPdf.tsx
  - src/components/pdf/RatingScalePdf.tsx

WHY IT FAILED: We were sanitizing rating data, but the corrupt value was
               actually in analysis.strengths[].frequency (AI-generated field)


COMMIT 2: 2f56048 (Tue Jan 6 15:33:33 2026)
--------------------------------------------
fix: filter out absurdly large corrupt rating values (e.g., -9.44e21)

WHAT WE THOUGHT: Number.isFinite() wasn't catching extremely large numbers
WHAT WE DID: Added explicit bounds check (Math.abs < 1e10)
FILES CHANGED:
  - src/components/pdf/ProjectInsightsPdf.tsx

WHY IT FAILED: Still focusing on rating values when the real culprit was
               in a completely different field (analysis.strengths[].frequency)


COMMIT 3: fcf59ae (Tue Jan 6 16:13:43 2026)
--------------------------------------------
fix: filter invalid ratings at the source in responseExtraction

WHAT WE THOUGHT: Need to filter at data extraction layer, not just PDF
WHAT WE DID: Added filtering in calculateRatingStats() function
FILES CHANGED:
  - src/lib/responseExtraction.ts

WHY IT FAILED: responseExtraction.ts only handles survey responses, not
               AI-generated analysis data


COMMIT 4: 73a01fa (Tue Jan 6 16:34:16 2026)
--------------------------------------------
fix: add safeNum function to sanitize all numbers in PDF rendering

WHAT WE THOUGHT: Need a universal sanitizer for all numbers in PDF
WHAT WE DID: Created safeNum() helper and applied to all numeric values
FILES CHANGED:
  - src/components/pdf/ProjectInsightsPdf.tsx

WHY IT FAILED: While this DID catch some numbers, it was still a band-aid
               approach - not addressing root cause of where corrupt data
               originates


COMMIT 5: 823b3de (Tue Jan 6 16:48:46 2026)
--------------------------------------------
fix: sanitize rating values in data extraction pipeline to prevent PDF crash

WHAT WE THOUGHT: Need to sanitize earlier in the pipeline
WHAT WE DID: Added sanitization in data extraction layer
FILES CHANGED:
  - src/lib/responseExtraction.ts
  - Additional validation layers

WHY IT FAILED: Again, focused on rating pipeline when the issue was in
               AI-generated analysis fields


COMMIT 6: cea1e38 (Tue Jan 6 17:05:43 2026)
--------------------------------------------
fix: sanitize ratingScale.max to prevent PDF crash with corrupt values

WHAT WE THOUGHT: The corrupt value is in question.ratingScale.max from template
WHAT WE DID: Sanitized ratingScale.max in responseExtraction.ts and PDF
FILES CHANGED:
  - src/lib/responseExtraction.ts
  - src/components/pdf/ProjectInsightsPdf.tsx

WHY IT FAILED: ratingScale.max was not the source - it was AI-generated
               analysis.strengths[].frequency that contained -9.44e21


COMMIT 7: 9048890 (Wed Jan 7 08:12:58 2026)
--------------------------------------------
fix: normalize rating data at source to prevent PDF crashes

WHAT WE THOUGHT: This is the "ROOT CAUSE FIX" with multi-layer approach
WHAT WE DID:
  - Server-side validation in convex/messages.ts
  - Data normalization in responseExtraction.ts
  - Component guards in RatingScaleDisplay.tsx
FILES CHANGED:
  - convex/messages.ts
  - src/lib/responseExtraction.ts
  - src/components/analysis/RatingScaleDisplay.tsx
  - src/components/pdf/ProjectInsightsPdf.tsx

WHY IT FAILED: Comprehensive fix for rating data, but STILL didn't address
               the actual source: AI-generated analysis fields


COMMIT 8: 7410493 (Wed Jan 7 08:36:35 2026)
--------------------------------------------
fix: sanitize AI-generated analysis data (frequency, coverage counts)

WHAT WE THOUGHT: Finally found it! The corrupt value is in analysis.strengths[].frequency
WHAT WE DID:
  - Added z.preprocess() sanitizers in schemas.ts for frequency (1-100)
  - Added z.preprocess() sanitizers for coverage counts (0-1000)
  - Added safeCount() guard in ProjectInsightsPdf.tsx
FILES CHANGED:
  - src/lib/schemas.ts
  - src/components/pdf/ProjectInsightsPdf.tsx

WHY IT FAILED: ❌ BUG STILL PRESENT IN NEW SURVEYS
               The sanitization happens AFTER the AI generates the data.
               The AI is STILL GENERATING corrupt values which means:
               1. The schema validation might not be catching it properly
               2. OR there's another field we haven't sanitized yet
               3. OR the AI continues to generate these values in new analysis


================================================================================
ACTUAL ROOT CAUSE (HYPOTHESIS)
================================================================================

The corrupt number -9.44473296573929e+21 is being GENERATED by the AI model
(Claude Haiku 4.5) during the analysis phase. This happens when:

1. AI analyzes survey responses via src/app/api/analyze/route.ts
2. AI generates JSON with analysis.strengths[].frequency field
3. AI sometimes outputs NaN, Infinity, or huge numbers instead of 1-100
4. These values pass through (or bypass) Zod validation
5. They get stored in the database
6. PDF rendering crashes when trying to render "Mentioned by -9.44e21 respondents"

THE REAL FIX NEEDED:
-------------------
❌ NOT band-aids at PDF layer
❌ NOT sanitization after AI generation
✅ PREVENT AI from generating corrupt values in the first place
✅ OR catch and reject at the moment of AI response parsing
✅ OR add robust fallback/retry when AI generates invalid numbers


AFFECTED FILES (from all 8 commits):
------------------------------------
- src/components/pdf/ProjectInsightsPdf.tsx (modified 6 times!)
- src/components/pdf/RatingScalePdf.tsx
- src/lib/responseExtraction.ts (modified 4 times!)
- src/lib/schemas.ts (modified 2 times)
- src/components/analysis/RatingScaleDisplay.tsx
- convex/messages.ts


NEXT STEPS (NOT YET ATTEMPTED):
-------------------------------
1. Check src/app/api/analyze/route.ts - How is AI response parsed?
2. Add validation IMMEDIATELY after AI generates JSON
3. Add retry logic if AI generates corrupt values
4. Consider using AI SDK's generateObject with stricter schema validation
5. Add explicit error handling for NaN/Infinity in AI responses
6. Possibly add additional constraints in the AI prompt to prevent this


TIMELINE:
---------
Started: Jan 6, 2026 (morning)
Last attempt: Jan 7, 2026 (morning)
Total commits: 8
Total files modified: 6 files, some multiple times
Status: ❌ STILL BROKEN


================================================================================
LESSON LEARNED
================================================================================

We spent 8 commits (over 24 hours) fixing symptoms instead of the root cause.
Each fix addressed ONE manifestation of corrupt data, but didn't prevent NEW
corrupt data from being generated. This is a classic example of:

1. Band-aid fixes instead of root cause analysis
2. Defensive programming taken too far (sanitizing in 6 different places)
3. Not tracing the data flow from SOURCE (AI generation) to SINK (PDF render)

The correct approach should have been:
1. WHERE does this number come from? (AI generation, not database)
2. WHEN is it created? (During analysis API call)
3. HOW can we prevent it? (Validation at AI response parsing)
4. WHY is AI generating it? (Prompt issue? Model issue? Schema issue?)

================================================================================
